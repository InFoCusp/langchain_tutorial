{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Installs"
      ],
      "metadata": {
        "id": "XORbazN4blRF"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "5FTyKnqlN4Hk",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "927379ea-943c-40aa-93fe-8a3313d33249"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting langchain\n",
            "  Downloading langchain-0.0.321-py3-none-any.whl (1.9 MB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/1.9 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.5/1.9 MB\u001b[0m \u001b[31m16.3 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m \u001b[32m1.9/1.9 MB\u001b[0m \u001b[31m28.6 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.9/1.9 MB\u001b[0m \u001b[31m22.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.10/dist-packages (from langchain) (6.0.1)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.0.22)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.10/dist-packages (from langchain) (3.8.6)\n",
            "Requirement already satisfied: anyio<4.0 in /usr/local/lib/python3.10/dist-packages (from langchain) (3.7.1)\n",
            "Requirement already satisfied: async-timeout<5.0.0,>=4.0.0 in /usr/local/lib/python3.10/dist-packages (from langchain) (4.0.3)\n",
            "Collecting dataclasses-json<0.7,>=0.5.7 (from langchain)\n",
            "  Downloading dataclasses_json-0.6.1-py3-none-any.whl (27 kB)\n",
            "Collecting jsonpatch<2.0,>=1.33 (from langchain)\n",
            "  Downloading jsonpatch-1.33-py2.py3-none-any.whl (12 kB)\n",
            "Collecting langsmith<0.1.0,>=0.0.43 (from langchain)\n",
            "  Downloading langsmith-0.0.49-py3-none-any.whl (41 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m41.9/41.9 kB\u001b[0m \u001b[31m4.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy<2,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain) (1.23.5)\n",
            "Requirement already satisfied: pydantic<3,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain) (1.10.13)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.31.0)\n",
            "Requirement already satisfied: tenacity<9.0.0,>=8.1.0 in /usr/local/lib/python3.10/dist-packages (from langchain) (8.2.3)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (23.1.0)\n",
            "Requirement already satisfied: charset-normalizer<4.0,>=2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (3.3.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (6.0.4)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.9.2)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.4.0)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.3.1)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/dist-packages (from anyio<4.0->langchain) (3.4)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.10/dist-packages (from anyio<4.0->langchain) (1.3.0)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<4.0->langchain) (1.1.3)\n",
            "Collecting marshmallow<4.0.0,>=3.18.0 (from dataclasses-json<0.7,>=0.5.7->langchain)\n",
            "  Downloading marshmallow-3.20.1-py3-none-any.whl (49 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.4/49.4 kB\u001b[0m \u001b[31m5.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting typing-inspect<1,>=0.4.0 (from dataclasses-json<0.7,>=0.5.7->langchain)\n",
            "  Downloading typing_inspect-0.9.0-py3-none-any.whl (8.8 kB)\n",
            "Collecting jsonpointer>=1.9 (from jsonpatch<2.0,>=1.33->langchain)\n",
            "  Downloading jsonpointer-2.4-py2.py3-none-any.whl (7.8 kB)\n",
            "Requirement already satisfied: typing-extensions>=4.2.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1->langchain) (4.5.0)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (2023.7.22)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from SQLAlchemy<3,>=1.4->langchain) (3.0.0)\n",
            "Requirement already satisfied: packaging>=17.0 in /usr/local/lib/python3.10/dist-packages (from marshmallow<4.0.0,>=3.18.0->dataclasses-json<0.7,>=0.5.7->langchain) (23.2)\n",
            "Collecting mypy-extensions>=0.3.0 (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain)\n",
            "  Downloading mypy_extensions-1.0.0-py3-none-any.whl (4.7 kB)\n",
            "Installing collected packages: mypy-extensions, marshmallow, jsonpointer, typing-inspect, langsmith, jsonpatch, dataclasses-json, langchain\n",
            "Successfully installed dataclasses-json-0.6.1 jsonpatch-1.33 jsonpointer-2.4 langchain-0.0.321 langsmith-0.0.49 marshmallow-3.20.1 mypy-extensions-1.0.0 typing-inspect-0.9.0\n",
            "Collecting pypdf\n",
            "  Downloading pypdf-3.16.4-py3-none-any.whl (276 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m276.6/276.6 kB\u001b[0m \u001b[31m7.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: pypdf\n",
            "Successfully installed pypdf-3.16.4\n",
            "Collecting google-generativeai\n",
            "  Downloading google_generativeai-0.2.2-py3-none-any.whl (133 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m133.2/133.2 kB\u001b[0m \u001b[31m4.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting google-ai-generativelanguage==0.3.3 (from google-generativeai)\n",
            "  Downloading google_ai_generativelanguage-0.3.3-py3-none-any.whl (267 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m267.9/267.9 kB\u001b[0m \u001b[31m16.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: google-auth in /usr/local/lib/python3.10/dist-packages (from google-generativeai) (2.17.3)\n",
            "Requirement already satisfied: google-api-core in /usr/local/lib/python3.10/dist-packages (from google-generativeai) (2.11.1)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.10/dist-packages (from google-generativeai) (3.20.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from google-generativeai) (4.66.1)\n",
            "Requirement already satisfied: proto-plus<2.0.0dev,>=1.22.0 in /usr/local/lib/python3.10/dist-packages (from google-ai-generativelanguage==0.3.3->google-generativeai) (1.22.3)\n",
            "Requirement already satisfied: googleapis-common-protos<2.0.dev0,>=1.56.2 in /usr/local/lib/python3.10/dist-packages (from google-api-core->google-generativeai) (1.61.0)\n",
            "Requirement already satisfied: requests<3.0.0.dev0,>=2.18.0 in /usr/local/lib/python3.10/dist-packages (from google-api-core->google-generativeai) (2.31.0)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth->google-generativeai) (5.3.1)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth->google-generativeai) (0.3.0)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from google-auth->google-generativeai) (1.16.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth->google-generativeai) (4.9)\n",
            "Requirement already satisfied: grpcio<2.0dev,>=1.33.2 in /usr/local/lib/python3.10/dist-packages (from google-api-core->google-generativeai) (1.59.0)\n",
            "Requirement already satisfied: grpcio-status<2.0.dev0,>=1.33.2 in /usr/local/lib/python3.10/dist-packages (from google-api-core->google-generativeai) (1.48.2)\n",
            "Requirement already satisfied: pyasn1<0.6.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth->google-generativeai) (0.5.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0.dev0,>=2.18.0->google-api-core->google-generativeai) (3.3.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0.dev0,>=2.18.0->google-api-core->google-generativeai) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0.dev0,>=2.18.0->google-api-core->google-generativeai) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0.dev0,>=2.18.0->google-api-core->google-generativeai) (2023.7.22)\n",
            "Installing collected packages: google-ai-generativelanguage, google-generativeai\n",
            "Successfully installed google-ai-generativelanguage-0.3.3 google-generativeai-0.2.2\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "google"
                ]
              }
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting chromadb\n",
            "  Downloading chromadb-0.4.14-py3-none-any.whl (448 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/448.1 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m \u001b[32m440.3/448.1 kB\u001b[0m \u001b[31m16.4 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m448.1/448.1 kB\u001b[0m \u001b[31m11.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: requests>=2.28 in /usr/local/lib/python3.10/dist-packages (from chromadb) (2.31.0)\n",
            "Requirement already satisfied: pydantic>=1.9 in /usr/local/lib/python3.10/dist-packages (from chromadb) (1.10.13)\n",
            "Collecting chroma-hnswlib==0.7.3 (from chromadb)\n",
            "  Downloading chroma_hnswlib-0.7.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.4/2.4 MB\u001b[0m \u001b[31m63.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting fastapi>=0.95.2 (from chromadb)\n",
            "  Downloading fastapi-0.104.0-py3-none-any.whl (92 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m92.9/92.9 kB\u001b[0m \u001b[31m11.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting uvicorn[standard]>=0.18.3 (from chromadb)\n",
            "  Downloading uvicorn-0.23.2-py3-none-any.whl (59 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m59.5/59.5 kB\u001b[0m \u001b[31m6.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting posthog>=2.4.0 (from chromadb)\n",
            "  Downloading posthog-3.0.2-py2.py3-none-any.whl (37 kB)\n",
            "Requirement already satisfied: typing-extensions>=4.5.0 in /usr/local/lib/python3.10/dist-packages (from chromadb) (4.5.0)\n",
            "Collecting pulsar-client>=3.1.0 (from chromadb)\n",
            "  Downloading pulsar_client-3.3.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (5.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.4/5.4 MB\u001b[0m \u001b[31m101.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting onnxruntime>=1.14.1 (from chromadb)\n",
            "  Downloading onnxruntime-1.16.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (6.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.2/6.2 MB\u001b[0m \u001b[31m95.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting tokenizers>=0.13.2 (from chromadb)\n",
            "  Downloading tokenizers-0.14.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.8/3.8 MB\u001b[0m \u001b[31m103.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting pypika>=0.48.9 (from chromadb)\n",
            "  Downloading PyPika-0.48.9.tar.gz (67 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m67.3/67.3 kB\u001b[0m \u001b[31m8.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: tqdm>=4.65.0 in /usr/local/lib/python3.10/dist-packages (from chromadb) (4.66.1)\n",
            "Collecting overrides>=7.3.1 (from chromadb)\n",
            "  Downloading overrides-7.4.0-py3-none-any.whl (17 kB)\n",
            "Requirement already satisfied: importlib-resources in /usr/local/lib/python3.10/dist-packages (from chromadb) (6.1.0)\n",
            "Requirement already satisfied: grpcio>=1.58.0 in /usr/local/lib/python3.10/dist-packages (from chromadb) (1.59.0)\n",
            "Collecting bcrypt>=4.0.1 (from chromadb)\n",
            "  Downloading bcrypt-4.0.1-cp36-abi3-manylinux_2_28_x86_64.whl (593 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m593.7/593.7 kB\u001b[0m \u001b[31m49.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: typer>=0.9.0 in /usr/local/lib/python3.10/dist-packages (from chromadb) (0.9.0)\n",
            "Requirement already satisfied: numpy>=1.22.5 in /usr/local/lib/python3.10/dist-packages (from chromadb) (1.23.5)\n",
            "Requirement already satisfied: anyio<4.0.0,>=3.7.1 in /usr/local/lib/python3.10/dist-packages (from fastapi>=0.95.2->chromadb) (3.7.1)\n",
            "Collecting starlette<0.28.0,>=0.27.0 (from fastapi>=0.95.2->chromadb)\n",
            "  Downloading starlette-0.27.0-py3-none-any.whl (66 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m67.0/67.0 kB\u001b[0m \u001b[31m8.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting typing-extensions>=4.5.0 (from chromadb)\n",
            "  Downloading typing_extensions-4.8.0-py3-none-any.whl (31 kB)\n",
            "Collecting coloredlogs (from onnxruntime>=1.14.1->chromadb)\n",
            "  Downloading coloredlogs-15.0.1-py2.py3-none-any.whl (46 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.0/46.0 kB\u001b[0m \u001b[31m5.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: flatbuffers in /usr/local/lib/python3.10/dist-packages (from onnxruntime>=1.14.1->chromadb) (23.5.26)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from onnxruntime>=1.14.1->chromadb) (23.2)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.10/dist-packages (from onnxruntime>=1.14.1->chromadb) (3.20.3)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from onnxruntime>=1.14.1->chromadb) (1.12)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from posthog>=2.4.0->chromadb) (1.16.0)\n",
            "Collecting monotonic>=1.5 (from posthog>=2.4.0->chromadb)\n",
            "  Downloading monotonic-1.6-py2.py3-none-any.whl (8.2 kB)\n",
            "Collecting backoff>=1.10.0 (from posthog>=2.4.0->chromadb)\n",
            "  Downloading backoff-2.2.1-py3-none-any.whl (15 kB)\n",
            "Requirement already satisfied: python-dateutil>2.1 in /usr/local/lib/python3.10/dist-packages (from posthog>=2.4.0->chromadb) (2.8.2)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from pulsar-client>=3.1.0->chromadb) (2023.7.22)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.28->chromadb) (3.3.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.28->chromadb) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.28->chromadb) (2.0.7)\n",
            "Collecting huggingface_hub<0.18,>=0.16.4 (from tokenizers>=0.13.2->chromadb)\n",
            "  Downloading huggingface_hub-0.17.3-py3-none-any.whl (295 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m295.0/295.0 kB\u001b[0m \u001b[31m31.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: click<9.0.0,>=7.1.1 in /usr/local/lib/python3.10/dist-packages (from typer>=0.9.0->chromadb) (8.1.7)\n",
            "Collecting h11>=0.8 (from uvicorn[standard]>=0.18.3->chromadb)\n",
            "  Downloading h11-0.14.0-py3-none-any.whl (58 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m6.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting httptools>=0.5.0 (from uvicorn[standard]>=0.18.3->chromadb)\n",
            "  Downloading httptools-0.6.1-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (341 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m341.4/341.4 kB\u001b[0m \u001b[31m36.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting python-dotenv>=0.13 (from uvicorn[standard]>=0.18.3->chromadb)\n",
            "  Downloading python_dotenv-1.0.0-py3-none-any.whl (19 kB)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from uvicorn[standard]>=0.18.3->chromadb) (6.0.1)\n",
            "Collecting uvloop!=0.15.0,!=0.15.1,>=0.14.0 (from uvicorn[standard]>=0.18.3->chromadb)\n",
            "  Downloading uvloop-0.19.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.4/3.4 MB\u001b[0m \u001b[31m95.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting watchfiles>=0.13 (from uvicorn[standard]>=0.18.3->chromadb)\n",
            "  Downloading watchfiles-0.21.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m79.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting websockets>=10.4 (from uvicorn[standard]>=0.18.3->chromadb)\n",
            "  Downloading websockets-12.0-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (130 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m130.2/130.2 kB\u001b[0m \u001b[31m15.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.10/dist-packages (from anyio<4.0.0,>=3.7.1->fastapi>=0.95.2->chromadb) (1.3.0)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<4.0.0,>=3.7.1->fastapi>=0.95.2->chromadb) (1.1.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface_hub<0.18,>=0.16.4->tokenizers>=0.13.2->chromadb) (3.12.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from huggingface_hub<0.18,>=0.16.4->tokenizers>=0.13.2->chromadb) (2023.6.0)\n",
            "Collecting humanfriendly>=9.1 (from coloredlogs->onnxruntime>=1.14.1->chromadb)\n",
            "  Downloading humanfriendly-10.0-py2.py3-none-any.whl (86 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m86.8/86.8 kB\u001b[0m \u001b[31m11.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->onnxruntime>=1.14.1->chromadb) (1.3.0)\n",
            "Building wheels for collected packages: pypika\n",
            "  Building wheel for pypika (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pypika: filename=PyPika-0.48.9-py2.py3-none-any.whl size=53723 sha256=2326ac91010e62cb7ede6eec5e0e69d35394be9b41c7553950006cd7d8cd088c\n",
            "  Stored in directory: /root/.cache/pip/wheels/e1/26/51/d0bffb3d2fd82256676d7ad3003faea3bd6dddc9577af665f4\n",
            "Successfully built pypika\n",
            "Installing collected packages: pypika, monotonic, websockets, uvloop, typing-extensions, python-dotenv, pulsar-client, overrides, humanfriendly, httptools, h11, chroma-hnswlib, bcrypt, backoff, watchfiles, uvicorn, starlette, posthog, huggingface_hub, coloredlogs, tokenizers, onnxruntime, fastapi, chromadb\n",
            "  Attempting uninstall: typing-extensions\n",
            "    Found existing installation: typing_extensions 4.5.0\n",
            "    Uninstalling typing_extensions-4.5.0:\n",
            "      Successfully uninstalled typing_extensions-4.5.0\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "lida 0.0.10 requires kaleido, which is not installed.\n",
            "lida 0.0.10 requires python-multipart, which is not installed.\n",
            "tensorflow-probability 0.22.0 requires typing-extensions<4.6.0, but you have typing-extensions 4.8.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed backoff-2.2.1 bcrypt-4.0.1 chroma-hnswlib-0.7.3 chromadb-0.4.14 coloredlogs-15.0.1 fastapi-0.104.0 h11-0.14.0 httptools-0.6.1 huggingface_hub-0.17.3 humanfriendly-10.0 monotonic-1.6 onnxruntime-1.16.1 overrides-7.4.0 posthog-3.0.2 pulsar-client-3.3.0 pypika-0.48.9 python-dotenv-1.0.0 starlette-0.27.0 tokenizers-0.14.1 typing-extensions-4.8.0 uvicorn-0.23.2 uvloop-0.19.0 watchfiles-0.21.0 websockets-12.0\n",
            "Collecting colorama\n",
            "  Downloading colorama-0.4.6-py2.py3-none-any.whl (25 kB)\n",
            "Installing collected packages: colorama\n",
            "Successfully installed colorama-0.4.6\n"
          ]
        }
      ],
      "source": [
        "! pip install langchain\n",
        "\n",
        "# Load PDFs.\n",
        "! pip install pypdf\n",
        "\n",
        "# Access to the Google Palm API\n",
        "! pip install google-generativeai\n",
        "\n",
        "# Database for embeddings\n",
        "! pip install chromadb\n",
        "\n",
        "# Colored output\n",
        "! pip install colorama"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Imports and setup"
      ],
      "metadata": {
        "id": "fm89a4zlbsNY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from colorama import Fore"
      ],
      "metadata": {
        "id": "Z5UWcUGQOHwb"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Connect to drive.\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8Rz3iBmRcCM0",
        "outputId": "601e4c7e-abdc-429a-b2d0-05175824ad9b"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Palm Setup"
      ],
      "metadata": {
        "id": "W7yYP6c9c3_K"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Generate yours @ https://developers.generativeai.google/products/palm\n",
        "with open('/content/drive/My Drive/key.txt', 'r') as f:\n",
        "  palm_api_key = f.readlines()[0].strip('\\n')\n",
        "\n",
        "os.environ[\"GOOGLE_API_KEY\"] = palm_api_key"
      ],
      "metadata": {
        "id": "kiw-kyJ4OKRU"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import langchain\n",
        "from langchain.prompts import PromptTemplate\n",
        "from langchain.llms.google_palm import GooglePalm\n",
        "from langchain.embeddings.google_palm import GooglePalmEmbeddings\n",
        "\n",
        "llm = GooglePalm(temperature=0.0, max_output_tokens=256)\n",
        "embeddings = GooglePalmEmbeddings()"
      ],
      "metadata": {
        "id": "b8qGy9soc8KL"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Ingestion Phase"
      ],
      "metadata": {
        "id": "N_XHkgiLdHJB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.document_loaders import PyPDFLoader\n",
        "from langchain.text_splitter import CharacterTextSplitter\n",
        "from langchain.vectorstores import Chroma"
      ],
      "metadata": {
        "id": "BOBWNXf2dLBf"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "doc_path = \"https://www.abc.xyz/assets/86/99/68122c444c4a93d2228e21ecc16b/20230426-alphabet-10q.pdf\"\n",
        "loader = PyPDFLoader(doc_path)\n",
        "text_splitter = CharacterTextSplitter(\n",
        "    chunk_size=512, chunk_overlap=0, separator=\"\\n\"\n",
        ")\n",
        "\n",
        "# load\n",
        "documents = loader.load()\n",
        "# split\n",
        "texts = text_splitter.split_documents(documents)\n",
        "# embed and store\n",
        "vector_store = Chroma.from_documents(\n",
        "    texts, embeddings, collection_name=\"google_2023\", persist_directory=\"./\"\n",
        ")"
      ],
      "metadata": {
        "id": "30Hl5HNUSFpX"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Exploring Stored Data\n",
        "data = vector_store._collection.peek(5)\n",
        "for idx, (id, embedding, metadata, document) in enumerate(zip(\n",
        "    data[\"ids\"], data[\"embeddings\"], data[\"metadatas\"], data[\"documents\"]\n",
        ")):\n",
        "  print(Fore.YELLOW + \"# Document \" + str(idx + 1) + \"\\n\\n\" + Fore.RESET)\n",
        "  print(Fore.BLUE + \"Id: \" + Fore.RESET + id + \"\\n\")\n",
        "  print(Fore.BLUE + \"Embedding: \" + Fore.RESET + str(embedding)[:40] + \" ...\\n\")\n",
        "  print(Fore.BLUE + \"Metadata: \" + Fore.RESET + str(metadata) + \"\\n\")\n",
        "  print(\n",
        "      Fore.BLUE + \"Text: \\n\\n\" + Fore.RESET\n",
        "      + document\n",
        "      + \"\\n\\n------------------------------------------------------------ \\n\"\n",
        "  )"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "cellView": "form",
        "id": "nUD1uMGGNnH6",
        "outputId": "673e5f1c-93b5-4c6b-c930-df38e9544dc1"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[33m# Document 1\n",
            "\n",
            "\u001b[39m\n",
            "\u001b[34mId: \u001b[39m6adfd2ca-71d9-11ee-82fb-0242ac1c000c\n",
            "\n",
            "\u001b[34mEmbedding: \u001b[39m[-0.007248384412378073, 0.01239798404276 ...\n",
            "\n",
            "\u001b[34mMetadata: \u001b[39m{'page': 0, 'source': '/tmp/tmp2cvv8we5/tmp.pdf'}\n",
            "\n",
            "\u001b[34mText: \n",
            "\n",
            "\u001b[39mUNITED STATES\n",
            "SECURITIES AND EXCHANGE COMMISSION\n",
            "Washington, D.C. 20549\n",
            "________________________________________________________________________________________\n",
            "FORM 10-Q  \n",
            "________________________________________________________________________________________\n",
            "(Mark One)\n",
            "☒ QUARTERLY REPORT PURSUANT TO SECTION 13 OR 15(d) OF THE SECURITIES EXCHANGE ACT OF 1934\n",
            "For the quarterly period ended March 31, 2023\n",
            "OR\n",
            "☐ TRANSITION REPORT PURSUANT TO SECTION 13 OR 15(d) OF THE SECURITIES EXCHANGE ACT OF 1934\n",
            "\n",
            "------------------------------------------------------------ \n",
            "\n",
            "\u001b[33m# Document 2\n",
            "\n",
            "\u001b[39m\n",
            "\u001b[34mId: \u001b[39m6adfd4fa-71d9-11ee-82fb-0242ac1c000c\n",
            "\n",
            "\u001b[34mEmbedding: \u001b[39m[-0.004968447610735893, -0.0063596065156 ...\n",
            "\n",
            "\u001b[34mMetadata: \u001b[39m{'page': 0, 'source': '/tmp/tmp2cvv8we5/tmp.pdf'}\n",
            "\n",
            "\u001b[34mText: \n",
            "\n",
            "\u001b[39mFor the transition period from _______ to _______\n",
            "Commission file number: 001-37580  \n",
            "________________________________________________________________________________________\n",
            "Alphabet Inc.  \n",
            "(Exact name of registrant as specified in its charter)\n",
            "________________________________________________________________________________________\n",
            "Delaware 61-1767919\n",
            "(State or other jurisdiction of incorporation or organization) (I.R.S. Employer Identification Number)\n",
            "1600 Amphitheatre Parkway\n",
            "Mountain View , CA 94043\n",
            "\n",
            "------------------------------------------------------------ \n",
            "\n",
            "\u001b[33m# Document 3\n",
            "\n",
            "\u001b[39m\n",
            "\u001b[34mId: \u001b[39m6adfd6b2-71d9-11ee-82fb-0242ac1c000c\n",
            "\n",
            "\u001b[34mEmbedding: \u001b[39m[-0.000964079808909446, -0.0158256012946 ...\n",
            "\n",
            "\u001b[34mMetadata: \u001b[39m{'page': 0, 'source': '/tmp/tmp2cvv8we5/tmp.pdf'}\n",
            "\n",
            "\u001b[34mText: \n",
            "\n",
            "\u001b[39m(Address of principal executive offices, including zip code)\n",
            "(650) 253-0000\n",
            "(Registrant's telephone number, including area code)\n",
            "Securities registered pursuant to Section 12(b) of the Act:\n",
            "Title of each class Trading Symbol(s) Name of each exchange on which registered\n",
            "Class A Common Stock, $0.001 par value GOOGL Nasdaq Stock Market LLC\n",
            "(Nasdaq Global Select Market)\n",
            "Class C Capital Stock, $0.001 par value GOOG Nasdaq Stock Market LLC\n",
            "(Nasdaq Global Select Market)\n",
            "\n",
            "------------------------------------------------------------ \n",
            "\n",
            "\u001b[33m# Document 4\n",
            "\n",
            "\u001b[39m\n",
            "\u001b[34mId: \u001b[39m6adfd77a-71d9-11ee-82fb-0242ac1c000c\n",
            "\n",
            "\u001b[34mEmbedding: \u001b[39m[0.026943108066916466, 0.008100776001811 ...\n",
            "\n",
            "\u001b[34mMetadata: \u001b[39m{'page': 0, 'source': '/tmp/tmp2cvv8we5/tmp.pdf'}\n",
            "\n",
            "\u001b[34mText: \n",
            "\n",
            "\u001b[39m________________________________________________________________________________________\n",
            "Indicate by check mark whether the registrant: (1) has filed all reports required to be filed by Section 13 or 15(d) of the Securities \n",
            "Exchange Act of 1934 during the preceding 12 months (or for such shorter period that the registrant was required to file such \n",
            "reports), and (2) has been subject to such filing requirements for the past 90 days.    Yes  ☒    No  ☐\n",
            "\n",
            "------------------------------------------------------------ \n",
            "\n",
            "\u001b[33m# Document 5\n",
            "\n",
            "\u001b[39m\n",
            "\u001b[34mId: \u001b[39m6adfd7fc-71d9-11ee-82fb-0242ac1c000c\n",
            "\n",
            "\u001b[34mEmbedding: \u001b[39m[0.010438675992190838, -0.02086065150797 ...\n",
            "\n",
            "\u001b[34mMetadata: \u001b[39m{'page': 0, 'source': '/tmp/tmp2cvv8we5/tmp.pdf'}\n",
            "\n",
            "\u001b[34mText: \n",
            "\n",
            "\u001b[39mIndicate by check mark whether the registrant has submitted electronically every Interactive Data File required to be submitted \n",
            "pursuant to Rule 405 of Regulation S-T (§232.405 of this chapter) during the preceding 12 months (or for such shorter period \n",
            "that the registrant was required to submit such files).    Yes  ☒    No  ☐\n",
            "Indicate by check mark whether the registrant is a large accelerated filer, an accelerated filer, a non-accelerated filer, a smaller\n",
            "\n",
            "------------------------------------------------------------ \n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Generation Phase"
      ],
      "metadata": {
        "id": "EEZgIdQld63o"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title prompt\n",
        "prompt_template = PromptTemplate.from_template(\n",
        "    \"You are finance expert who is tasked with finidng insights about a  \\n\"\n",
        "    \"company from text. Please answer the question at the end using the \\n\"\n",
        "    \"information given below. \\n\"\n",
        "    \"\\n------------------------------------\\n\"\n",
        "    \"Information: \\n\"\n",
        "    \"{context}\"\n",
        "    \"\\n------------------------------------\\n\"\n",
        "    \"Question: \\n\"\n",
        "    \"{question}\"\n",
        ")"
      ],
      "metadata": {
        "cellView": "form",
        "id": "YZyUeN5p_bsa"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 1. user asks query\n",
        "query = \"What was Google's total income from operations in 2022?\"\n",
        "# 2. langchain gets context\n",
        "retriever = vector_store.as_retriever(search_kwargs={\"k\": 3})\n",
        "relevant_docs = retriever.get_relevant_documents(query=query)\n",
        "context = \"\\n ------------------------------------------------\\n\".join(\n",
        "    [doc.page_content for doc in relevant_docs]\n",
        ")\n",
        "# 3. generate response\n",
        "prompt = prompt_template.format(context=context, question=query)\n",
        "answer = llm(prompt)\n",
        "# 4. return response\n",
        "print(answer)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Vu0PzcAWSljL",
        "outputId": "78908068-d6f4-4b16-c496-6eec98654526"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Google's total income from operations in 2022 was $20,094.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Exploring Context\n",
        "\n",
        "for idx, document in enumerate(relevant_docs):\n",
        "  print(Fore.YELLOW + \"# Document \" + str(idx + 1) + \"\\n\\n\" + Fore.RESET)\n",
        "  print(\n",
        "      document.page_content\n",
        "      + \"\\n\\n------------------------------------------------------------ \\n\"\n",
        "  )"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "cellView": "form",
        "id": "OzoZbTKJk4cm",
        "outputId": "0fd8d9b0-3ac1-4c77-9635-bdba4e4fc5ae"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[33m# Document 1\n",
            "\n",
            "\u001b[39m\n",
            "Total revenues $ 68,011 $ 69,787 \n",
            " Three Months Ended\n",
            "March 31,\n",
            " 2022 2023\n",
            "Operating income (loss):\n",
            "Google Services $ 21,973 $ 21,737 \n",
            "Google Cloud  (706)  191 \n",
            "Other Bets  (835)  (1,225) \n",
            "Corporate costs, unallocated  (338)  (3,288) \n",
            "Total income from operations $ 20,094 $ 17,415 \n",
            "For revenues by geography, see Note 2 .\n",
            "The following table presents long-lived assets by geographic area, which includes property and equipment, net \n",
            "and operating lease assets (in millions) :\n",
            "As of \n",
            "December 31, 2022As of\n",
            "\n",
            "------------------------------------------------------------ \n",
            "\n",
            "\u001b[33m# Document 2\n",
            "\n",
            "\u001b[39m\n",
            "2022 2023\n",
            "Net cash provided by operating activities $ 25,106 $ 23,509 \n",
            "Net cash used in investing activities $ (9,051) $ (2,946) \n",
            "Net cash used in financing activities $ (16,214) $ (16,568) \n",
            "Cash Provided by Operating Activities\n",
            "Our largest source of cash provided by operations are advertising revenues generated by Google Search & \n",
            "other properties, Google Network properties, and YouTube properties. Additionally, we generate cash through sales\n",
            "\n",
            "------------------------------------------------------------ \n",
            "\n",
            "\u001b[33m# Document 3\n",
            "\n",
            "\u001b[39m\n",
            "Financial Results\n",
            "Revenues\n",
            "The following table presents revenues by type (in millions): \n",
            " Three Months Ended\n",
            "March 31,\n",
            " 2022 2023\n",
            "Google Search & other $ 39,618 $ 40,359 \n",
            "YouTube ads  6,869  6,693 \n",
            "Google Network  8,174  7,496 \n",
            "Google advertising  54,661  54,548 \n",
            "Google other  6,811  7,413 \n",
            "Google Services total  61,472  61,961 \n",
            "Google Cloud  5,821  7,454 \n",
            "Other Bets  440  288 \n",
            "Hedging gains (losses)  278  84 \n",
            "Total revenues $ 68,011 $ 69,787 \n",
            "Google Services\n",
            "Google advertising revenues\n",
            "\n",
            "------------------------------------------------------------ \n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Improving RAG"
      ],
      "metadata": {
        "id": "aYWmkhOAfE5b"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.retrievers import ContextualCompressionRetriever\n",
        "from langchain.retrievers.document_compressors import LLMChainExtractor\n",
        "\n",
        "compressor = LLMChainExtractor.from_llm(llm)\n",
        "compression_retriever = ContextualCompressionRetriever(\n",
        "    base_compressor=compressor,\n",
        "    base_retriever=vector_store.as_retriever(search_kwargs={\"k\": 3})\n",
        ")\n",
        "\n",
        "compressed_docs = compression_retriever.get_relevant_documents(query)"
      ],
      "metadata": {
        "id": "J0WU8S6ZJnOU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e9a3f055-2e29-4078-ec6f-f831e2c679a0"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/langchain/chains/llm.py:280: UserWarning: The predict_and_parse method is deprecated, instead pass an output parser directly to LLMChain.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/langchain/chains/llm.py:280: UserWarning: The predict_and_parse method is deprecated, instead pass an output parser directly to LLMChain.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/langchain/chains/llm.py:280: UserWarning: The predict_and_parse method is deprecated, instead pass an output parser directly to LLMChain.\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Compressed contexts\n",
        "data = vector_store._collection.peek(5)\n",
        "for idx, document in enumerate(compressed_docs):\n",
        "  print(Fore.YELLOW + \"# Document \" + str(idx + 1) + \"\\n\\n\" + Fore.RESET)\n",
        "  print(Fore.BLUE + \"Metadata: \" + Fore.RESET + str(document.metadata) + \"\\n\")\n",
        "  print(\n",
        "      Fore.BLUE + \"Text: \\n\\n\" + Fore.RESET\n",
        "      + document.page_content\n",
        "      + \"\\n\\n------------------------------------------------------------ \\n\"\n",
        "  )"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "cellView": "form",
        "id": "WAe8olSyBxb8",
        "outputId": "870984a9-9eab-49fd-c9e5-3067e46b5118"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[33m# Document 1\n",
            "\n",
            "\u001b[39m\n",
            "\u001b[34mMetadata: \u001b[39m{'page': 28, 'source': '/tmp/tmp2cvv8we5/tmp.pdf'}\n",
            "\n",
            "\u001b[34mText: \n",
            "\n",
            "\u001b[39mTotal income from operations $ 20,094\n",
            "\n",
            "------------------------------------------------------------ \n",
            "\n",
            "\u001b[33m# Document 2\n",
            "\n",
            "\u001b[39m\n",
            "\u001b[34mMetadata: \u001b[39m{'page': 39, 'source': '/tmp/tmp2cvv8we5/tmp.pdf'}\n",
            "\n",
            "\u001b[34mText: \n",
            "\n",
            "\u001b[39m2022 2023\n",
            "Net cash provided by operating activities $ 25,106 $ 23,509\n",
            "\n",
            "------------------------------------------------------------ \n",
            "\n",
            "\u001b[33m# Document 3\n",
            "\n",
            "\u001b[39m\n",
            "\u001b[34mMetadata: \u001b[39m{'page': 34, 'source': '/tmp/tmp2cvv8we5/tmp.pdf'}\n",
            "\n",
            "\u001b[34mText: \n",
            "\n",
            "\u001b[39mTotal revenues $ 68,011 $ 69,787\n",
            "\n",
            "------------------------------------------------------------ \n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Generating Answer\n",
        "context = \"\\n ------------------------------------------------\\n\".join(\n",
        "    [doc.page_content for doc in compressed_docs]\n",
        ")\n",
        "# 3. generate response\n",
        "prompt = prompt_template.format(context=context, question=query)\n",
        "answer = llm(prompt)\n",
        "# 4. return response\n",
        "print(answer)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "cellView": "form",
        "id": "w_RIOb2EDyZZ",
        "outputId": "6d0dc6e3-c176-4bd8-a2f3-b03763e7bf6f"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "20,094\n"
          ]
        }
      ]
    }
  ]
}